{"version":3,"sources":["../../tests/thegamma-tests/tokenizer.fs"],"names":[],"mappings":";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAAA;AAAA,cAeU,EAfV;;AAAA,sBAkBkB;AAAA;AAAA;AAAA;AAAQ,OAAR;AAAA;AAsBS,sBAAO,2HAAP;AAtBD,OAAR;AAAA;AAAA;AAAQ,OAAR;AAAA;AAwBS;AAxBD,OAAR;AAAA;AAAA;AAAQ,OAAR;AAAA;AAAA;AAAQ,OAAR,KA4BT;AAAA;AAA4B,OAA5B,EA5BS;AA4BmB,KA9CrC;;AAAA,uBAkDsD;AAAA,wCAA1C,mBAAkB;AAAA;AAAA,OAAlB,SAA0C;AAAgB,KAlDtE;;AAAA,iCAwDK;AAAA,wCADA,mBAAkB;AAAA,4CAAgC,2BAAhC;AAAA,OAAlB,SACA;AAAgB,KAxDrB;;AAAA,uBA4DgE;AAAA,aAA9D,+EAA8B;AAAA;AAAA,OAA9B,EAA8D;AAAa,KA5D7E;;AAAA,yBAgEE,yBAAE,gCAAF,EAAoB,gCAApB,EAAsC,gCAAtC,EAAwD,6BAAxD,EAAuE,+BAAvE,EACE,6BADF,EACiB,iCADjB,EACoC,iCADpC,EACuD,6BADvD,EACsE,+BADtE,EAEE,gCAAmB,+BAAnB,EAFF,EAEsC,gCAAmB,oCAAnB,EAFtC,EAGE,gCAAmB,2CAAnB,EAHF,EAGkD,gCAAmB,iCAAnB,EAHlD,EAIE,gCAAmB,wCAAnB,EAJF,EAI+C,gCAAmB,8BAAnB,EAJ/C,EAKE,gCAAmB,iCAAnB,EALF,EAKwC,gCAAmB,6BAAnB,EALxC,EAK0E,iCAL1E,EAME,qCANF,EAM0B,sCAN1B,EAhEF;;AAAA,sBA2EQ;AAAA;;AAEI;AAAA,kCAAM,gGAAN;;AAIiC;AAAA;AAAA;;AAJjC;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAsD,WAAtD;AAAA;AAAA;AAAsD,aAAtD;AAAA;AAAA;AAAsD,eAAtD;AAAA;AAAsD;AAAA;AAAA;AAAA,SAAtD;AAAA;AAAA;AAAA;AAAsD,aAAtD;AAAA;AAAsD;AAAA,WAAtD;AAAA;AAAsD;AAAA;AAAA,OAAtD;;AAFJ;AAAA;AAAA;AAAA;AAAA,wCAkBC,8BAAiB,wCAAjB,EAlBD,IAmBU,oCAnBV,IAoBF,6BAAgB,MAAM,iBAAtB,EApBE,GAqBC,+BArBD;AAAA;;AAAA,kCAeC;AAAA,mDAAiB,yCAAjB;AAA0D,aAf3D;AAAA;AAAA,oBAgBU;AAAA;AAAA;AAAA;;AAAA;AAAA;AAAI,mBAAJ;AAAA;AAAA;AAAI,qBAAJ;AAAA;AAAA;AAAI;AAAA,iBAAJ,EAhBV,EAiBF;AAAA,sDAAgB,MAAM,0BAAtB;AAAgD,iBAjB9C,MAgBU;AAAA;AAAI;AAhBF,eAAZ;AAAA;AAAY;AAAA;AAAA,WAAZ;;AAAA;AAAA,gBAWU;AAAA;AAAA;AAAA;;AAAA;AAAA;AAAI,eAAJ;AAAA;AAAA;AAAI,iBAAJ;AAAA;AAAA;AAAI;AAAA,aAAJ,EAXV,EAYE;AAAA;AACI,sDAAkB,uBAAlB;AACR,sDAAoB,oBAApB;AAFU,aAZR,MAWU;AAAA;AAAI;AAXF,WAAZ;AAAA;AAAY;AAAA,SAAZ;;AAAA;AAAA,cAQU;AAAA;AAAA;AAAA;;AAAA;AAAA;AAAI,aAAJ;AAAA;AAAA;AAAI,eAAJ;AAAA;AAAA;AAAI;AAAA,WAAJ,EARV,EASE;AAAI;AACR,iDAAiB,SAAjB;AADK,WATH,MAQU;AAAA;AAAI;AARF,SAAZ;AAAA;AAAY;AAAA,OAAZ;;AAAA;AAAA,YAC0D,CAAzB,sBAAa;AAAA;AAAA,SAAb,iBADjC,EACe;AAAA;AAA8C,SAD7D,MACe;AAAA;AAA8C;AADjD,OAAZ;AAAA;AAAA,cAC0D,CAAzB,sBAAa;AAAA;AAAA,WAAb,iBADjC,EACe;AAAA;AAA8C,WAD7D,MACe;AAAA;AAA8C;AADjD,SAAZ;AAAA;AAAA,gBAC0D,CAAzB,sBAAa;AAAA;AAAA,aAAb,iBADjC,EACe;AAAA;AAA8C,aAD7D,MACe;AAAA;AAA8C;AADjD,WAAZ;AAAA;AAAA,kBAC0D,CAAzB,sBAAa;AAAA;AAAA,eAAb,iBADjC,EACe;AAAA;AAA8C,eAD7D,MACe;AAAA;AAA8C;AADjD,aAAZ;AAAA;AAAY;AAAA;AAAA;AAAA;AAAA,KA3EpB;;AAAA,uBAyGK;AAAA,mCADA,oBAAU,gDAAV,EAHA,sBACG;AAAI,+BAAU,iBAAV,EAAoC,oBAApC;AAAJ;AAAC,OADJ,EADH,6BACG,CAGA,CACA;AAAU,KAzGf;;AAAA,0BA6GE;AAAA,qCACM;AAAS;AACH;;AACV,YAAG,IAAH,EACE;AAAQ,yEAAR;AAAA;AAAA;;AACU,iCAAmB;AAAQ,kDAAR;AAAA;AAAA,eAAoB,oBAApB;AAAwC,WAA3D;AAA4D;;AACxE;AALU;;AAMJ,qDAAR;AAAA;AAAA;AAA2B,KApH7B;;AAAA,sDA4HE;AAAA,sBACM;AAAuB,oDAAoB,0BAApB;AAC3B;AADwB,OAD1B;AAE8B,KA9HhC;AAAA,I","file":"tokenizer.js","sourceRoot":"c:/tomas/public/thegamma/thegamma-script/out/tests","sourcesContent":["ï»¿#if INTERACTIVE\r\n#r \"../../src/thegamma/bin/Debug/thegamma.dll\"\r\n#else\r\n[<NUnit.Framework.TestFixture>]\r\nmodule TheGamma.Tests.Tokenizer\r\n#endif\r\nopen TheGamma\r\nopen TheGamma.Tokenizer\r\nopen NUnit.Framework\r\n\r\n// --------------------------------------------------------------------------------------\r\n// Helpers for writing property tests for tokenizer\r\n// --------------------------------------------------------------------------------------\r\n\r\n/// Global random number generator\r\nlet rnd = System.Random()\r\n\r\n/// Format a single token\r\nlet formatToken = function\r\n  | TokenKind.LParen -> \"(\"\r\n  | TokenKind.RParen -> \")\"\r\n  | TokenKind.Equals -> \"=\"\r\n  | TokenKind.Dot -> \".\"\r\n  | TokenKind.Comma -> \",\"\r\n  | TokenKind.Let -> \"let\"\r\n  | TokenKind.LSquare -> \"[\"\r\n  | TokenKind.RSquare -> \"]\"\r\n  | TokenKind.Fun -> \"fun\"\r\n  | TokenKind.Arrow -> \"->\"\r\n  | TokenKind.Operator Operator.Divide -> \"/\"\r\n  | TokenKind.Operator Operator.GreaterThan -> \">\"\r\n  | TokenKind.Operator Operator.GreaterThanOrEqual -> \">=\"\r\n  | TokenKind.Operator Operator.LessThan -> \"<\"\r\n  | TokenKind.Operator Operator.LessThanOrEqual -> \"<=\"\r\n  | TokenKind.Operator Operator.Minus -> \"-\"\r\n  | TokenKind.Operator Operator.Multiply -> \"*\"\r\n  | TokenKind.Operator Operator.Plus -> \"+\"\r\n  | TokenKind.Boolean true -> \"true\"\r\n  | TokenKind.Boolean false -> \"false\"\r\n  | TokenKind.Number(s, _) -> s\r\n  | TokenKind.String(s) -> \"\\\"\" + s.Replace(\"\\\\\", \"\\\\\\\\\").Replace(\"\\n\", \"\\\\n\").Replace(\"\\\"\", \"\\\\\\\"\") + \"\\\"\"\r\n  | TokenKind.Ident(i) -> i\r\n  | TokenKind.QIdent(q) -> \"'\" + q + \"'\"\r\n  | TokenKind.White(w) -> w\r\n  | TokenKind.Newline -> \"\\n\"\r\n  | TokenKind.Error(c) -> string c\r\n  | _ -> failwith \"Unsupported token\"\r\n\r\n/// Turns series of tokens into string, using their Token value\r\nlet formatTokens (tokens:seq<Token>) = \r\n  tokens |> Seq.map (fun t -> formatToken t.Token) |> String.concat \"\"\r\n\r\n/// Turn series of tokens into string, using their Range and original input\r\nlet formatTokensUsingRange (source:string) (tokens:seq<Token>) = \r\n  tokens \r\n  |> Seq.map (fun t -> source.Substring(t.Range.Start, t.Range.End - t.Range.Start))\r\n  |> String.concat \"\"\r\n\r\n/// Generate short, potentially empty random string using characters from the given input string\r\nlet randomString (s:string) = \r\n  Array.init (rnd.Next 10) (fun _ -> s.[rnd.Next(s.Length)]) |> System.String\r\n\r\n/// List of tokens that do not have any parameters\r\nlet constantTokens = \r\n  [ TokenKind.LParen; TokenKind.RParen; TokenKind.Equals; TokenKind.Dot; TokenKind.Comma\r\n    TokenKind.Let; TokenKind.LSquare; TokenKind.RSquare; TokenKind.Fun; TokenKind.Arrow\r\n    TokenKind.Operator Operator.Divide; TokenKind.Operator Operator.GreaterThan\r\n    TokenKind.Operator Operator.GreaterThanOrEqual; TokenKind.Operator Operator.LessThan\r\n    TokenKind.Operator Operator.LessThanOrEqual; TokenKind.Operator Operator.Minus\r\n    TokenKind.Operator Operator.Multiply; TokenKind.Operator Operator.Plus; TokenKind.Newline \r\n    TokenKind.Boolean true; TokenKind.Boolean false ]\r\n\r\n/// Generate random token - takes last token to avoid generating token pairs that\r\n/// would be parsed differently (e.g. Number 1; Number 2 would be Number 12)\r\nlet randomToken last =\r\n  match rnd.Next(12) with\r\n  | 0 | 1 | 2 | 3 when constantTokens |> Seq.exists ((=) last) |> not -> \r\n      match last, constantTokens.[rnd.Next(constantTokens.Length)] with\r\n      | TokenKind.Ident _, TokenKind.Let\r\n      | TokenKind.Ident _, TokenKind.Fun\r\n      | TokenKind.Ident _, TokenKind.Boolean _ \r\n      | TokenKind.Number _, TokenKind.Dot -> TokenKind.Arrow\r\n      | _, t -> t\r\n  | 4 when (match last with TokenKind.Ident _ | TokenKind.Number _ -> false | _ -> true) -> \r\n      let n = rnd.Next(0, 1000000000)\r\n      TokenKind.Number(string n, float n)\r\n  | 5 when (match last with TokenKind.Ident _ | TokenKind.Number _ -> false | _ -> true) -> \r\n      let n1, n2 = rnd.Next(0, 1000000), rnd.Next(0, 1000000)\r\n      let n = string n1 + \".\" + string n2\r\n      TokenKind.Number(n, float n)\r\n  | 6 -> TokenKind.String(randomString \"abcDEF012$*^!@#+,. \\n\\\\\\\"\")\r\n  | 7 when (match last with TokenKind.Number _ | TokenKind.Ident _ -> false | _ -> true) -> \r\n      TokenKind.Ident(\"a\" + randomString \"bcdEFG0123\")\r\n  | 8 -> TokenKind.QIdent(randomString \"bcdEFG0123$*^!@#+,. \\\\\\\"\")\r\n  | _ when (match last with TokenKind.White _ -> false | _ -> true) -> \r\n      TokenKind.White(\" \" + randomString \" \")\r\n  | _ -> TokenKind.Comma\r\n\r\n/// Generate random array of tokens (with incorrect ranges)\r\nlet randomTokens () =   \r\n  TokenKind.Dot\r\n  |> Seq.unfold (fun last ->\r\n    let t = { Token = randomToken last; Range = { Start = 0; End = 0 } }\r\n    Some(t, t.Token))\r\n  |> Seq.take (20 + rnd.Next(100))\r\n  |> List.ofSeq\r\n\r\n/// Check property involving random tokens\r\nlet checkWithTokens f = \r\n  for i in 1 .. 100 do\r\n    let tokens = randomTokens()    \r\n    let res = f tokens\r\n    if not res then   \r\n      printfn \"*** Assertion failed ***\\nTokens:\"\r\n      tokens |> Seq.iter (fun t -> printfn \"  >>%s<<\" (formatToken t.Token))\r\n    Assert.AreEqual(true, res)\r\n  printfn \"Passed 100 tests.\"\r\n\r\n// --------------------------------------------------------------------------------------\r\n// Helpers for writing property tests for tokenizer\r\n// --------------------------------------------------------------------------------------\r\n\r\n[<Test>]\r\nlet ``Format and tokenize returns original tokens`` () =\r\n  checkWithTokens (fun sourceTokens ->  \r\n    let parsedTokens, errors = Tokenizer.tokenize (formatTokens sourceTokens)\r\n    parsedTokens = sourceTokens)\r\n"]}